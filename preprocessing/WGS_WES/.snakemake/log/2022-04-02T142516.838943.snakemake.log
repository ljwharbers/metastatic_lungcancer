Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 3
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	5	aflred_post
	1	all
	5	deduplication
	1	qc
	12
Select jobs to execute...

[Sat Apr  2 14:25:16 2022]
rule deduplication:
    input: /mnt/sequencing/BICRO320/bamfiles/S7_NEU_200ng.bam
    output: /mnt/sequencing/BICRO320/bamfiles/S7_NEU_200ng.dedup.bam, /mnt/sequencing/BICRO320/stats/S7_NEU_200ng.metrics.txt
    jobid: 3
    wildcards: sample=S7_NEU_200ng
    threads: 3

gatk MarkDuplicates -I /mnt/sequencing/BICRO320/bamfiles/S7_NEU_200ng.bam -O /mnt/sequencing/BICRO320/bamfiles/S7_NEU_200ng.dedup.bam -M /mnt/sequencing/BICRO320/stats/S7_NEU_200ng.metrics.txt
Terminating processes on user request, this might take some time.
[Sat Apr  2 14:35:38 2022]
Error in rule deduplication:
    jobid: 3
    output: /mnt/sequencing/BICRO320/bamfiles/S7_NEU_200ng.dedup.bam, /mnt/sequencing/BICRO320/stats/S7_NEU_200ng.metrics.txt
    shell:
        gatk MarkDuplicates -I /mnt/sequencing/BICRO320/bamfiles/S7_NEU_200ng.bam -O /mnt/sequencing/BICRO320/bamfiles/S7_NEU_200ng.dedup.bam -M /mnt/sequencing/BICRO320/stats/S7_NEU_200ng.metrics.txt
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Job failed, going on with independent jobs.
Complete log: /mnt/AchTeraD/Documents/Projects/LungCancer/manuscript/repository/preprocessing/WGS_WES/.snakemake/log/2022-04-02T142516.838943.snakemake.log
